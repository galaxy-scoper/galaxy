
* 什么是内存和设备池化？
设备池化(pooling)就是将计算资源、网络资源、存储资源做成一个池子，
按需在池内分配，达到物尽其用，为此CXL技术应运而生。
[[./Pictures/协议学习-2.png]]
一个SLD设备只能被分配到一个HOST上
一次完整的资源释放和重分配过程是：
假设过了一段时间，H1不需要D2设备了，在一个HOT-PLUG流程后，D2可
被HOT-REMOVE掉（不用真的物理移除），D2就被释放到POOL里了，假设再
过一段时间，H3设备需要更多的加速设备，它去POOL里一看，发现D2是空闲的
，D2就被HOT-ADD到H3上了，也就是说D2 Online到H3上。这就完成了一次池化
资源的释放与分配
[[./Pictures/协议学习-3.png]]
MLD设备池化过程
如上图，D1的所有内存被分配给了H1，D2的部分内存被分配给H1，部分给了H3，
假设过了一段时间，H3可通过HOT-REMOVE释放一些内存，释放的内存可通过
HOT-ADD到H1上。MLD的分配粒度更小，更灵活，

** 为什么搞CXL？
为了直接访问内存，可通过PCIE发起DMA操作来实现，这种方式虽然加快内存访问速度，
但也带来一此安全问题，DMA对内存的访问还要通过内存控制器，延迟很高，为解决这些
问题，Intel推出了I/OAT技术，DMA可直接访问CPU LLC Cache，但此方法未解决主存和
设备内存分离的问题，它们地址不能统一编址，缓存一致性不能保证。为解决这个问题，
才搞出的。解决方法不只有CXL，与CXL技术相近的技术比较有名的是INVIDA的NV-LINK。

* CXL是什么？
CXL是一种基于PCIE-IO的缓存一致性(Cache Coherency)互联标准。
CPU里的HomeAgent(HA)负责处理Cache的一致性问题（解决Conflict，收发Snoop等），每代
CPU HA都不同，要在设备中实现HA会极大增加设备复杂性，也会导致兼容性问题和难于定义
固定的标准协议。为此，CXL只包含Cache Agent(CA)，


** Flex Bus Link
提供一种点对点的互连，可支持PCIE或CXL.
这里可理解为CTRL,
[[./Pictures/协议学习-4.png]]

** CXL System Architecture
CXL是一种高性能I/O总线架构，用于互联外围设备。
CXL设备类型:
1. Type1
2. Type2
3. Type3
[[./Pictures/协议学习-5.png]]


type2和type3的内存向主机公开时，它被称为主机管理的设备内存(Host-Managed Device Memory)HDM
此存储器的一致性管理有三个选项：主机与设备必须对每个地址区域的HDM类型有共识。
1. Host-Only Coherent(HDM-H)
2. Device Coherent (HDM-D)
3. Device Coherent Using Back-Invalidation Snoop(HDM-DB)

对于NonCoherent-IO设备，由于这种主要依赖Producer-Consumer排序模型的设备，
它不访问主机内存。这类设备不需要CXL提供的强大功能，只需要使用PCIE*作为加速器
连接介质就足够了。

*** CXL-TYPE1 Device
CXL类型1设备具有特殊需求，因此在设备中拥有完全一致的缓存变得的很有价值。
具有特殊要求的设备的一个例子是执行复杂的原子操作，这些原子不属于PCIE上
标准原子操作套件。
基本缓存一致性允许加速器实现它选择的任何排序模型，并允许它实现无限
数据的原子操作。这些往往只需要一个小容量缓存，可很容易通过标准处理器监听
过滤器机制进行跟踪。此类设备可以支持的缓存大小取决主机的侦听过滤能力。
CXL使用其可选的CXL.cache链接支持此类设备，加速器可以通过该链接使用CXL.cache
协议进行缓存一致性事务。
[[./Pictures/协议学习-6.png]]

*** CXL-TYPE2
CXL类型2设备除了完全一致的缓存外，还具有连接到设备的内存，如DDR、高带宽内存(HBM)等。
这些设备针对内存执行操作，但它们的性能来自加速器和设备连接内存之间的大量带宽。
CXL的主要目标是为主机提供一种将操作数推送到设备连接内存的方法，以及为主机提供从设备
连接内存中提取结果的方法，以便它不会增加软件和硬件成本，从而抵消加速器的优势。
此规范将一致性系统地址映射的设备连接内存称为具有管理一致性的主机管理设备内存
(HDM-D/HDM-DB)
概括地说，有两种方法可解决HDM的器件一致性问题：
1. 使用CXL.cache来管理HDM的一致性，称“设备一致性”，支持此方法的内存区域使用后缀”D“表示
   HDM-D
2. 使用CXL.mem中称为BackInvalidation Snoop的专用通过，并用后缀"DB"HDM-DB来表示
**** Back-Invalidate Snoop Coherency for HDM-DB
HDM-DB:Host-Managed Device Memory-Device Back-Invalidate
借助HDM-DB，该协议在CXL.mem协议中启用了新通道，允许设备使用专用的反向失效侦听(BlSnp)
通道直接窥探主机。这些窥探的响应通道是反向失效响应(BlRsp)通道。这些通道允许设备灵活地
管理一致性，方法是对单个缓存行使用包容性侦听过滤器跟踪一致性，这些缓存行可能会阻止新的
M2S请求，直到主机处理BlSnp消息。使用HDM-DB时，本章节中描述的所有设备一致性跟踪选项也
是可能的。但是，流向HDM-DB主机的一致性流只能使用CXL.mem S2M BlSnp通道，面不能使用
D2H CXL.cache请求通道，所有实现256B Flit模式的设备都需要HDM-DB支持，但为了与
68B-Flit模式兼容，将支持HDM-D流。
**** Bias-Based Coherency Model for HDM-D Memory
"BIAS-BASED"是用于管理HDM一致性的一种模型，这个模型定义了两种"偏好"状态:
- HostBias(主机偏好)
  当设备附加的内存(device-attached memory)处于这种状态时，对设备来说，它就像普通的主机附加的内存(Host-Attached Memory)
  如果设备需要访问这块内存，它需要向主机发送一个请求。主机会负责解决数据一致性问题。
- DeviceBias(设备偏好)
  在这种状态下，设备可以确保主机的缓存中没有这块内存的任何数据
  设备可以直接访问这块内存，无需向主机发送任何请求或信号
可以通过描述数据流来解释这一过程。假设我们处在“HostBias”模式，并且设备想要修改存储在设备附加内存上某个数据项。
***** Host Bias模式下的数据
1. 请求发送  :设备首先发送一个请求到主机(Host)，告知主机它想要修改某个特定的内存位置。
2. 一致性检查:收到请求，主机会检查自己的缓存和内存系统，以确保关于这个特定内存位置的所有数据都是一致的
3. 权限授予  :一旦一致性得到保证，主机会给设备发送一个信号或许可，告诉设备现在可以进行数据修改
4. 数据写入  :设备在收到主机的许可后，会将新的数据写入到指定的设备附加内存位置
5. 确认操作  :设备完成数据写入后，可能会发送一个确认信号回主机，表明数据修改完成
6. 更新主机状态:主机收到确认后，会更新自己关于这块内存位置的缓存或状态信息，以反映最新的数据
** CXL传输层
*** CXL.io
CXL.io为I/O设备提供了非一致性的加载/存储接口，并且在Flex Bus层次结构中占据特定位置。
该协议遵循PCIe*定义的事务类型、事务层包格式、基于信用的流量控制、虚拟通道管理和事务排序规则。
欲知详情，请参考PCIe基础规范中的“事务层规范”章节。
对于CXL.io而言，值得注意的是它采用了一些PCIe操作模式或特性，比如用于重置和电源管理的PCIe厂商定义消息、支持加速器而修改的PCIe ATS请求与完成格式等。
*** CXL Power Management VDM 格式
CXL电源管理消息作为PCIE供应商定义的类型0消息发送，并带有4-DWORD数据有效负载。其中包括PMREQ、PMRSP和PMGO消息。
VDM:Vendor Defined Message

* PCIE-6.0协议
** PCIE协议的分层结构
PCIE协议划分为事务层/数据链路层/物理层, 这些层中的每一层分为两个部分, 一部分是发送数据内容, 一部分是接收信息.
[[./Pictures/协议学习-3.1.1.png]]
[[./Pictures/协议学习-3.1.2.png]]
*** 事务层
事务层是PCIE协议的对外接口层, 用户对数据进行组帧和解帧是在本层进行, 本层产生的数据包称之为事务包数据包,
此外事务层还具有基于信用积分的流控功能, 支持不同事务类型的不同形式的数据传输.
**** 事务层的包格式
事务层由请求和完成两种类型组成, 是基于包的方式进行端到端的数据交换.针对6.0协议, 分为flit-mode/non-flit-mode
[[./Pictures/协议学习-3.1.1.1.10.png]]NonFiltMode
[[./Pictures/协议学习-3.1.1.1.100.png]]FlitMode

一个TLP由1个或多个TLP-PREFIX(前缀)/TLP-HEADER/PAYLOAD/可选的TLP-DIGEST(摘要)
PCIE有个DW的概念, 1DW = 4Bytes = 32bits, 从左端为低字节序.
TLP-PREFIX的概念主要用于扩展TLP功能. 分为两种: local tlp prefix和 end-to-end tlp prefix.它们的目的是为了提
供额外的信息或控制, 从而增强PCIE的功能和性能
TLP-DIGEST是附加到TLP的一种校验机制, 用于确保TLP的内容在传输过程中未被篡改或损坏.它通常由一个校验和类似的
校验数据组成, 这个校验数据是基于TLP内容计算得出的且固定的32bit

PCIE-TLP包分3DW和4DW两种, 根据地址是32bit还是64bit.
[[./Pictures/协议学习-3.1.1.1.11.png]]
- FMT: 头数据中FMT/TYPE配合起来就可表示所有PCIE的包类型:
|----------+----------------|
| FMT[2:0] | TLP FORMAT     |
|----------+----------------|
| 000b     | 3DW, NO DATE   |
| 001b     | 4DW, NO DATE   |
| 010b     | 3DW, WITH DATE |
| 011b     | 4DW, WITH DATE |
| 100b     | TLP PREFIX     |
|          | RSVD           |
|----------+----------------|

- TYPE
|-------+----------+---------+-------------------------------------------------|
| TLP   | FMT      | TYPE    | DESCRIPTION                                     |
|-------+----------+---------+-------------------------------------------------|
| M-RD  | 000/001b | 0_0000b | 内存读请求, 支持帧头为3DW/4DW, 不含数据段       |
| MRdLK | 000/001b | 0_0001b | 锁定的内存读请求, 支持帧头为3dw/4dw, 不含数据段 |
| MWr   | 010/011b | 0_0000b | 内存写请求, 支持帧头为3dw/4dw, 含数据           |
|       |          |         |                                                 |

- TC: Traffic Class
  表示事务优先级, 默认0, 数值越大优先级越高. 与虚拟通道(VC)有关系, 优先级不同的数据报文可使用不同的虚拟通路,
  每一虚拟通路可独立设置缓冲, 从而可使得优先级高的优先传输. 这也解决了服务质量([[Quality of Service][QOS]])的问题.
  
- ATTR
  [[./Pictures/协议学习-3.1.1.1.13.png]]
  IO-Based Ordering
*** 数据链路层
主要职责包括链路管理和数据完整性, 包括错误检测和纠正.
数据链路层在传输路上接收事务层的TLP添加 *序列号和核验码* 交给物理层, 并进行缓存, 如果检测传输错误会进行重
发, 直到接收正确或正确链路通信失败.
链路层还具有链路管理功能, 并有相应的数据包(DLLP), 该数据包实现两个组件间的数据交换, 并没有路由功能, 主
要实现流量控制, 电源管理, 应答机制和虚拟通道.
[[./Pictures/协议学习-3.1.2.1.png]]
下图是DLLP包的组成形式, 包含一个字节来表示DLLP数据包的类型, 3个额外字节表示该类型数据包所携带的内容,最
2字节作为包校验. 这一共是6B, 实际上DLLP是8B, 如果物理层采用8B/10B编码会给数据包添加1B的SDP和1B的END控制
符, SDP(start of DLLP)表示开始, END表示结束. 如果采用128B/130B编码, 那会在帧头添加2B的SDP, 帧尾不加结束
符.
[[./Pictures/协议学习-3.1.2.2.png]]
[[./Pictures/协议学习-3.1.2.3.png]]
**** ACK/NAK机制
DLLP包始于数据链路层也止于数据链路层.ACK/NAK机制只应该数据链路层.
如果接收端成功接收就返回一个ACK的DLLP包, 如果接收端发现有问题, 就返馈一个NAK的DLLP包.
基本数据流:
1. 发送端接收到事务层的TLP后添加sequence和LCRC后发送出去, 接收端收到后去除TLP的sequence和LCRC发送到事
   务层
2. 接收端根据判断结果反馈ACK/NAK数据包到发送端, 发送端接收到后根据DLLP内容做出响应处理.
**** 发送端保证可靠传输的方法
[[./Pictures/协议学习-3.1.2.2.1.png]]
由上图可知, 分三个部分.
1. 第一部分
   对收到的TLP包添加sequence和LCRC, 并写入缓冲区, 缓冲区写到一定程度会反压事务层的写操作
2. 第二部分
   添加序列号, NEXT_TRANSMIT_SEQ(NTS)表示下一个加添加的序列号, 在向"Assign Sequence Number"传递一个
   值会加一, AS是ACKED_SEQ的缩写, 表示接收端发送过来的ACK/NAK的序列号, 如果差值大于2048为会反压事务层
3. 第三部分
   处理接收端反馈的DLLP, 这里是ACK/NAK, 处理顺序如下:
   1. 进行CRC校验, 校验失败直接丟掉
   2. 序列号比较, 序列号比较又分为多种情况, 大致为, 如果是ACK, 则接收端接收正常, 发送端根据ACK中的序
      列号, 将缓存区里的不大于该值的TLP释放掉, 如果是NAK说明接收端接收端异常, 同样根据NAK包中序列号将
      缓存区中不大于该值的释放掉, 其它的进行重传.
*** 物理层
分两个部分:
- 逻辑子层, 负责与数据链路层的数据交换, 会对接收链路层进行再次封装, 对接收电气子层事务进行解析, 并会进
  行8B/10B或128B/130B编码, 进行传递之间转换和极性反转等工作
- 电气子层, 则更多的负责时钟数据恢复/均衡等电气操作

** PCIE协议的事务类型
PCIE协议总共定义了MEM/IO/CFG/MSG四种事务类型
*** 内存事务
它并一定是读写内存, 而是代表一种大数据量的数据交换方式, PCIE支持内存事务类型的读写以及原子操作(AtomicOp)
内存地址空间支持读/写/原子操作请求这三大类事务类型,支持短地址32bit和长地址64bit两种地址空间.


*** I/O事务
I/O事务是被PCIE嫌弃的一类事务, 会逐渐被MMIO替代.
MMIO(Memory-Mapped I/O, 内存映射I/O)是一种访问设备寄存器和配置空间的机制. 在PCIE架构中, MMIO是一种I/O
访问方法, 它允许软件通过内存地址范围来读取或写入设备寄存器的值而不是通过传统的I/O端口方式.

IO地址空间用于I/O事务, 允许设备使用类似传统IO端口的方式进行通信和数据传输. 支持读/写的请求与完成, 支持的地址格式是32bit.

*** 配置事务
每个PCIE设备都有一组配置寄存器, 包含设备的重要信息/功能设置以及与设备通信所需的控制寄存器等. 在PCIE设备
使用前必须经过配置阶段

配置地址空间对应配置事务, 用于访问设备的配置寄存器. 通过配置地址空间系统可对设备进行初始化/配置/管理.
事务类型包含两种类型:
1. 读事务, 主机系统通过PCIE总线向目标设备的配置空间读取信息. 通常涉及读取设备的配置寄存器, 以获取设备的
   状态/特性/其它信息
2. 写事务, 主机系统通过pcie总线向目标设备的配置空间写入信息.
   
*** 消息事务
消息是PCIE新增的一种事务类型, 用来取代PCI的一些边带信号, 使得所有的信号传递都通过报文实现. PCIE支持的消
息事务有中断/电源管理/错误消息等8项

MSG地址空间用于提供了一种灵活的数据传输机制, 使得设备之间可以通过异步的方式进行通信, 从而更好地支持一些
事件驱动的场景, 例如中断传递/错误通知/电源管理等
** PCIE的传输机制
数据交换是基于请求与完成(响应)的机制, 分为Non-Posted(需响应)和Posted(不需响应)两种模式. 只有MSG/MEM-WR是
不需要响应的(P报文), 其它都是NP报文
|--------------------------------------+----------------------|
| Transaction Type                     | Non-Posted or Posted |
| MEM_RD                               | P                    |
| Memory write                         | NP                   |
| Memory Read Lock                     | NP                   |
| IO read                              | NP                   |
| IO write                             | NP                   |
| Configuration Read(type0 and type1)  | NP                   |
| Configuration Write(type0 and type1) | NP                   |
| Message                              | P                    |

** PCIE的路由方案
路由强调的是发送端和接收端间的方案, 与之对应的是点对点通信.
点对点通信不考虑拥塞等问题, 而路由链路可能很长, 中间有很多的中转站.
*** ID路由
ID路由即BDF路由方案, 即采用BusNumber/DeviceNumber/FunctionNumber来确定目标设备的位置. 这是一种兼容PCI
的路由方案, 主要用于设备的配置/带数据和不带数据的返回数据包. 
*** 地址路由
地址路由由包含对IO/MEM两种事务类型的路由, 由帧头中包含的目的设备的地址信息, 处理器会为每个设备分配一段
地址信息, 这也是数据包传输过程中的标志符.
*** 模糊路由
模糊路由(又称为隐式路由)只能用于MSG类型事务的路由. 用来实现电源管理/错误信号/热插拔/虚拟通道等功能

** PCIE的拓扑结构
[[./Pictures/协议学习-3.5.png]]

*** RC(root complex)
RC是实现CPU与PCIE上组件通信的媒介, 负责初始化和管理PCIE总线上的所有设备.
RC支持的主要功能有:
1. 配置空间管理: RC管理PCIE总线上所有设备的配置空间. 每个PCIE设备都有一组配置寄存器, 这些寄存器储存设备
   的特定信息, 如设备ID, 厂商ID.
2. 地址映射: RC负责分配PCIE总线上各个设备的地址. 这包含内存映射和IO映射,以确保不同设备之间的数据传输能
   够正确进行.
3. 中断管理: PCIE设备可能会生成中断信号, RC负责管理这些中断, 确保它们正确地传递到相应的处理器核心.
4. 通信与数据传输: RC与其它PCIE设备之前通过PCIE链路进行通信. PCIE链路分为一到多个通道, 每个通道包含一个
   上行和一个下行通道, 用于双向数据传输.

*** EP(EndPoints)

RC的命令最终要去的地方是EP. 它是PCIE总线上的终端设备, 负责提供各种服务和数据传输功能.
一般称之为PCIE设备, 或者是PCIE Agent, 在PCIE规范里经常看到, 我们知道他们指代的是功能组件即可.

*** SWITCH
作用好比路由器, 是扩展PCIE总线的, 能够允许更多的EP设备链接到总线.
它的内部可以视为多个虚拟PCI到PCI的桥, 实现扩展功能. 该组件对数据包没有处理的功能只有转发的功能.
[[./Pictures/协议学习-3.5.3.png]]

*** PCIE到PCI/PCI-X桥接器
这个主要是用来兼容PCI组件, 如果有设备是PCI接口, 可以通过PCIE-PCI桥来接入系统. 

** Quality of Service
QoS机制用于描述和管理系统中数据传输的性能和优先级. QoS机制确保在带宽有限的情况下, 关键的或高优先级的流量能够得到必要的
资源, 以保证服务质量(如低延迟和高吞吐量)
QoS主要关注以下几方面:
[[./Pictures/协议学习-3.1.1.1.12.png]]
